#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ç®¡ç†æ¨¡å—
å®ç°SQLiteæ•°æ®åº“é›†æˆï¼Œæ”¯æŒä»»åŠ¡çŠ¶æ€å­˜å‚¨ã€å†å²è®°å½•æŸ¥çœ‹å’Œæ–­ç‚¹ç»­ä¼ 
"""

import os
import sqlite3
import json
import time
import threading
from typing import Dict, List, Optional, Any, Tuple, Callable
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass, asdict
from contextlib import contextmanager

@dataclass
class TaskInfo:
    """ä»»åŠ¡ä¿¡æ¯æ•°æ®ç»“æ„"""
    task_id: str
    status: str  # pending, processing, complete, error, cancelled
    created_at: float
    updated_at: float
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    zip_file_path: Optional[str] = None
    excel_file_path: Optional[str] = None
    zip_file_name: Optional[str] = None
    excel_file_name: Optional[str] = None
    progress_percent: float = 0.0
    current_step: Optional[str] = None
    total_materials: int = 0
    processed_materials: int = 0
    report_content: Optional[str] = None
    formatted_report: Optional[str] = None
    error_message: Optional[str] = None
    file_size_mb: float = 0.0
    processing_time_seconds: float = 0.0
    cache_hits: int = 0
    cache_misses: int = 0
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TaskInfo':
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        return cls(**data)

@dataclass
class TaskLog:
    """ä»»åŠ¡æ—¥å¿—æ•°æ®ç»“æ„"""
    log_id: Optional[int]
    task_id: str
    timestamp: float
    level: str  # INFO, WARN, ERROR, DEBUG
    message: str
    step: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: Optional[str] = None, progress_callback: Optional[Callable[[str], None]] = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„database.db
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        """
        self.progress_callback = progress_callback or (lambda msg: None)
        
        # è®¾ç½®æ•°æ®åº“è·¯å¾„
        if db_path:
            self.db_path = Path(db_path)
        else:
            self.db_path = Path(__file__).parent / "database.db"
        
        # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # çº¿ç¨‹é”ï¼Œç¡®ä¿æ•°æ®åº“æ“ä½œçš„çº¿ç¨‹å®‰å…¨
        self.lock = threading.RLock()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
        
        self._log(f"ğŸ“Š æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        self._log(f"   ğŸ“ æ•°æ®åº“è·¯å¾„: {self.db_path}")
        
    def _log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        if self.progress_callback:
            self.progress_callback(message)
    
    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        with self.lock:
            conn = sqlite3.connect(str(self.db_path), timeout=30.0)
            conn.row_factory = sqlite3.Row  # ä½¿ç»“æœå¯ä»¥é€šè¿‡åˆ—åè®¿é—®
            try:
                yield conn
            finally:
                conn.close()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # åˆ›å»ºä»»åŠ¡è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS tasks (
                    task_id TEXT PRIMARY KEY,
                    status TEXT NOT NULL,
                    created_at REAL NOT NULL,
                    updated_at REAL NOT NULL,
                    start_time REAL,
                    end_time REAL,
                    zip_file_path TEXT,
                    excel_file_path TEXT,
                    zip_file_name TEXT,
                    excel_file_name TEXT,
                    progress_percent REAL DEFAULT 0.0,
                    current_step TEXT,
                    total_materials INTEGER DEFAULT 0,
                    processed_materials INTEGER DEFAULT 0,
                    report_content TEXT,
                    formatted_report TEXT,
                    error_message TEXT,
                    file_size_mb REAL DEFAULT 0.0,
                    processing_time_seconds REAL DEFAULT 0.0,
                    cache_hits INTEGER DEFAULT 0,
                    cache_misses INTEGER DEFAULT 0
                )
            """)
            
            # åˆ›å»ºä»»åŠ¡æ—¥å¿—è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS task_logs (
                    log_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    task_id TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    level TEXT NOT NULL,
                    message TEXT NOT NULL,
                    step TEXT,
                    FOREIGN KEY (task_id) REFERENCES tasks (task_id)
                )
            """)
            
            # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks (status)
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks (created_at)
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_task_logs_task_id ON task_logs (task_id)
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_task_logs_timestamp ON task_logs (timestamp)
            """)
            
            conn.commit()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ•°æ®åº“å‡çº§
            self._upgrade_database(cursor)
            conn.commit()
    
    def _upgrade_database(self, cursor):
        """æ•°æ®åº“å‡çº§é€»è¾‘"""
        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ–°å­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ·»åŠ 
            cursor.execute("PRAGMA table_info(tasks)")
            columns = [row[1] for row in cursor.fetchall()]
            
            # æ·»åŠ æ–°å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            new_columns = [
                ('progress_percent', 'REAL DEFAULT 0.0'),
                ('current_step', 'TEXT'),
                ('total_materials', 'INTEGER DEFAULT 0'),
                ('processed_materials', 'INTEGER DEFAULT 0'),
                ('file_size_mb', 'REAL DEFAULT 0.0'),
                ('processing_time_seconds', 'REAL DEFAULT 0.0'),
                ('cache_hits', 'INTEGER DEFAULT 0'),
                ('cache_misses', 'INTEGER DEFAULT 0'),
            ]
            
            for column_name, column_def in new_columns:
                if column_name not in columns:
                    cursor.execute(f"ALTER TABLE tasks ADD COLUMN {column_name} {column_def}")
                    self._log(f"   ğŸ”§ æ•°æ®åº“å‡çº§: æ·»åŠ å­—æ®µ {column_name}")
                    
        except Exception as e:
            self._log(f"âš ï¸ æ•°æ®åº“å‡çº§è­¦å‘Š: {e}")
    
    def create_task(self, task_info: TaskInfo) -> bool:
        """
        åˆ›å»ºæ–°ä»»åŠ¡
        
        Args:
            task_info: ä»»åŠ¡ä¿¡æ¯
            
        Returns:
            æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ’å…¥ä»»åŠ¡è®°å½•
                cursor.execute("""
                    INSERT INTO tasks (
                        task_id, status, created_at, updated_at, start_time, end_time,
                        zip_file_path, excel_file_path, zip_file_name, excel_file_name,
                        progress_percent, current_step, total_materials, processed_materials,
                        report_content, formatted_report, error_message,
                        file_size_mb, processing_time_seconds, cache_hits, cache_misses
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    task_info.task_id, task_info.status, task_info.created_at, task_info.updated_at,
                    task_info.start_time, task_info.end_time, task_info.zip_file_path, task_info.excel_file_path,
                    task_info.zip_file_name, task_info.excel_file_name, task_info.progress_percent,
                    task_info.current_step, task_info.total_materials, task_info.processed_materials,
                    task_info.report_content, task_info.formatted_report, task_info.error_message,
                    task_info.file_size_mb, task_info.processing_time_seconds, task_info.cache_hits, task_info.cache_misses
                ))
                
                conn.commit()
                return True
                
        except Exception as e:
            self._log(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def update_task(self, task_id: str, updates: Dict[str, Any]) -> bool:
        """
        æ›´æ–°ä»»åŠ¡ä¿¡æ¯
        
        Args:
            task_id: ä»»åŠ¡ID
            updates: è¦æ›´æ–°çš„å­—æ®µå­—å…¸
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            if not updates:
                return True
                
            # è‡ªåŠ¨æ·»åŠ æ›´æ–°æ—¶é—´
            updates['updated_at'] = time.time()
            
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ„å»ºUPDATEè¯­å¥
                set_clauses = []
                values = []
                for key, value in updates.items():
                    set_clauses.append(f"{key} = ?")
                    values.append(value)
                
                values.append(task_id)
                
                sql = f"UPDATE tasks SET {', '.join(set_clauses)} WHERE task_id = ?"
                cursor.execute(sql, values)
                
                conn.commit()
                return cursor.rowcount > 0
                
        except Exception as e:
            self._log(f"âŒ æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def get_task(self, task_id: str) -> Optional[TaskInfo]:
        """
        è·å–ä»»åŠ¡ä¿¡æ¯
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            ä»»åŠ¡ä¿¡æ¯æˆ–None
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM tasks WHERE task_id = ?", (task_id,))
                row = cursor.fetchone()
                
                if row:
                    return TaskInfo(**dict(row))
                return None
                
        except Exception as e:
            self._log(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: {e}")
            return None
    
    def get_tasks_by_status(self, status: str, limit: int = 100) -> List[TaskInfo]:
        """
        æ ¹æ®çŠ¶æ€è·å–ä»»åŠ¡åˆ—è¡¨
        
        Args:
            status: ä»»åŠ¡çŠ¶æ€
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            ä»»åŠ¡ä¿¡æ¯åˆ—è¡¨
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM tasks 
                    WHERE status = ? 
                    ORDER BY created_at DESC 
                    LIMIT ?
                """, (status, limit))
                
                rows = cursor.fetchall()
                return [TaskInfo(**dict(row)) for row in rows]
                
        except Exception as e:
            self._log(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_recent_tasks(self, limit: int = 20) -> List[TaskInfo]:
        """
        è·å–æœ€è¿‘çš„ä»»åŠ¡åˆ—è¡¨
        
        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            ä»»åŠ¡ä¿¡æ¯åˆ—è¡¨
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM tasks 
                    ORDER BY created_at DESC 
                    LIMIT ?
                """, (limit,))
                
                rows = cursor.fetchall()
                return [TaskInfo(**dict(row)) for row in rows]
                
        except Exception as e:
            self._log(f"âŒ è·å–æœ€è¿‘ä»»åŠ¡å¤±è´¥: {e}")
            return []
    
    def add_task_log(self, task_log: TaskLog) -> bool:
        """
        æ·»åŠ ä»»åŠ¡æ—¥å¿—
        
        Args:
            task_log: ä»»åŠ¡æ—¥å¿—
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO task_logs (task_id, timestamp, level, message, step)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    task_log.task_id, task_log.timestamp, task_log.level,
                    task_log.message, task_log.step
                ))
                
                conn.commit()
                return True
                
        except Exception as e:
            self._log(f"âŒ æ·»åŠ ä»»åŠ¡æ—¥å¿—å¤±è´¥: {e}")
            return False
    
    def get_task_logs(self, task_id: str, limit: int = 1000) -> List[TaskLog]:
        """
        è·å–ä»»åŠ¡æ—¥å¿—
        
        Args:
            task_id: ä»»åŠ¡ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            ä»»åŠ¡æ—¥å¿—åˆ—è¡¨
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM task_logs 
                    WHERE task_id = ? 
                    ORDER BY timestamp ASC 
                    LIMIT ?
                """, (task_id, limit))
                
                rows = cursor.fetchall()
                return [TaskLog(**dict(row)) for row in rows]
                
        except Exception as e:
            self._log(f"âŒ è·å–ä»»åŠ¡æ—¥å¿—å¤±è´¥: {e}")
            return []
    
    def delete_task(self, task_id: str) -> bool:
        """
        åˆ é™¤ä»»åŠ¡ï¼ˆåŒ…æ‹¬ç›¸å…³æ—¥å¿—ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # åˆ é™¤ä»»åŠ¡æ—¥å¿—
                cursor.execute("DELETE FROM task_logs WHERE task_id = ?", (task_id,))
                
                # åˆ é™¤ä»»åŠ¡
                cursor.execute("DELETE FROM tasks WHERE task_id = ?", (task_id,))
                
                conn.commit()
                return cursor.rowcount > 0
                
        except Exception as e:
            self._log(f"âŒ åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def cleanup_old_tasks(self, days_old: int = 30) -> int:
        """
        æ¸…ç†æ—§ä»»åŠ¡
        
        Args:
            days_old: åˆ é™¤å¤šå°‘å¤©å‰çš„ä»»åŠ¡
            
        Returns:
            åˆ é™¤çš„ä»»åŠ¡æ•°é‡
        """
        try:
            cutoff_time = time.time() - (days_old * 24 * 3600)
            
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # è·å–è¦åˆ é™¤çš„ä»»åŠ¡
                cursor.execute("""
                    SELECT task_id FROM tasks 
                    WHERE created_at < ? AND status IN ('complete', 'error', 'cancelled')
                """, (cutoff_time,))
                
                old_task_ids = [row[0] for row in cursor.fetchall()]
                
                if old_task_ids:
                    # åˆ é™¤ä»»åŠ¡æ—¥å¿—
                    placeholders = ','.join(['?'] * len(old_task_ids))
                    cursor.execute(f"DELETE FROM task_logs WHERE task_id IN ({placeholders})", old_task_ids)
                    
                    # åˆ é™¤ä»»åŠ¡
                    cursor.execute(f"DELETE FROM tasks WHERE task_id IN ({placeholders})", old_task_ids)
                    
                    conn.commit()
                    
                    self._log(f"ğŸ§¹ æ¸…ç†äº† {len(old_task_ids)} ä¸ªæ—§ä»»åŠ¡")
                    return len(old_task_ids)
                
                return 0
                
        except Exception as e:
            self._log(f"âŒ æ¸…ç†æ—§ä»»åŠ¡å¤±è´¥: {e}")
            return 0
    
    def get_task_statistics(self) -> Dict[str, Any]:
        """
        è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # åŸºæœ¬ç»Ÿè®¡
                cursor.execute("SELECT COUNT(*) FROM tasks")
                total_tasks = cursor.fetchone()[0]
                
                cursor.execute("SELECT status, COUNT(*) FROM tasks GROUP BY status")
                status_counts = dict(cursor.fetchall())
                
                # æœ€è¿‘7å¤©çš„ä»»åŠ¡
                week_ago = time.time() - (7 * 24 * 3600)
                cursor.execute("SELECT COUNT(*) FROM tasks WHERE created_at > ?", (week_ago,))
                recent_tasks = cursor.fetchone()[0]
                
                # å¹³å‡å¤„ç†æ—¶é—´
                cursor.execute("""
                    SELECT AVG(processing_time_seconds) 
                    FROM tasks 
                    WHERE status = 'complete' AND processing_time_seconds > 0
                """)
                avg_processing_time = cursor.fetchone()[0] or 0
                
                # æˆåŠŸç‡
                success_count = status_counts.get('complete', 0)
                error_count = status_counts.get('error', 0)
                success_rate = (success_count / (success_count + error_count) * 100) if (success_count + error_count) > 0 else 0
                
                return {
                    'total_tasks': total_tasks,
                    'status_counts': status_counts,
                    'recent_tasks_7days': recent_tasks,
                    'average_processing_time_seconds': round(avg_processing_time, 2),
                    'success_rate_percent': round(success_rate, 2),
                    'database_size_mb': round(os.path.getsize(self.db_path) / 1024 / 1024, 2) if self.db_path.exists() else 0
                }
                
        except Exception as e:
            self._log(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def export_task_data(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        å¯¼å‡ºä»»åŠ¡æ•°æ®ï¼ˆç”¨äºå¤‡ä»½æˆ–åˆ†æï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            åŒ…å«ä»»åŠ¡ä¿¡æ¯å’Œæ—¥å¿—çš„å®Œæ•´æ•°æ®
        """
        try:
            task_info = self.get_task(task_id)
            if not task_info:
                return None
            
            task_logs = self.get_task_logs(task_id)
            
            return {
                'task_info': task_info.to_dict(),
                'logs': [log.to_dict() for log in task_logs],
                'export_time': time.time()
            }
            
        except Exception as e:
            self._log(f"âŒ å¯¼å‡ºä»»åŠ¡æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_resumable_tasks(self) -> List[TaskInfo]:
        """
        è·å–å¯æ¢å¤çš„ä»»åŠ¡ï¼ˆçŠ¶æ€ä¸ºprocessingä½†é•¿æ—¶é—´æœªæ›´æ–°ï¼‰
        
        Returns:
            å¯æ¢å¤çš„ä»»åŠ¡åˆ—è¡¨
        """
        try:
            # è¶…è¿‡1å°æ—¶æœªæ›´æ–°çš„processingä»»åŠ¡è®¤ä¸ºå¯èƒ½éœ€è¦æ¢å¤
            stale_time = time.time() - 3600
            
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM tasks 
                    WHERE status = 'processing' AND updated_at < ?
                    ORDER BY updated_at ASC
                """, (stale_time,))
                
                rows = cursor.fetchall()
                return [TaskInfo(**dict(row)) for row in rows]
                
        except Exception as e:
            self._log(f"âŒ è·å–å¯æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
            return []
    
    def backup_database(self, backup_path: str) -> bool:
        """
        å¤‡ä»½æ•°æ®åº“
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦å¤‡ä»½æˆåŠŸ
        """
        try:
            import shutil
            shutil.copy2(str(self.db_path), backup_path)
            self._log(f"ğŸ’¾ æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_path}")
            return True
            
        except Exception as e:
            self._log(f"âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def optimize_database(self) -> bool:
        """
        ä¼˜åŒ–æ•°æ®åº“ï¼ˆé‡å»ºç´¢å¼•ã€æ¸…ç†ç©ºé—´ï¼‰
        
        Returns:
            æ˜¯å¦ä¼˜åŒ–æˆåŠŸ
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # é‡å»ºç´¢å¼•
                cursor.execute("REINDEX")
                
                # æ¸…ç†æ•°æ®åº“
                cursor.execute("VACUUM")
                
                conn.commit()
                
            self._log("ğŸ”§ æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            self._log(f"âŒ æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {e}")
            return False